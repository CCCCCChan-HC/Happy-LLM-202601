# Task3
## 心得&笔记&疑问&解答：

- [知识点] 从计算机视觉为起源的神经网络，核心架构三种：
    - FNN全连接：层内节点全连接
    - CNN卷积：中间层节点数比较少→抽象出特征？
    - RNN循环：输出作为输入

- [QA] Q: **三者的区别和架构区别的影响在哪？**
    > A: 
        - **FNN**：层内节点全连接，导致无法区分输入数据的空间/时序关系（如文本中词的顺序、图像中像素的位置），仅能学习全局特征映射，因此仅适用于简单分类（如MNIST手写数字），不适用于结构化数据（文本、图像）。
        - **CNN**：通过**卷积核**捕捉局部模式（如图像的边缘、文本的n-gram短语），再通过**池化**聚合全局信息，核心优势是“空间/局部结构建模”，但**无法处理时序依赖**（如文本中“他”指代前文的“小明”）。
        - **RNN**：循环结构→“时序依赖建模”——通过隐藏状态保存历史信息（如前一个词的语义），核心优势是“序列顺序感知”，但**并行性差、长距离依赖弱**。

- [QA] Q: 这句话怎么理解：“由于NLP任务所需要处理的文本往往是序列，因此专用于处理序列，时序数据的RNN往往能够在NLP任务上取得最优的效果”
    > A: →**顺序matters（“顺序决定语义”）所以是序列，但是RNN处理序列的优势怎么理解和推出来的？**
        >> A: RNN通过循环结构将历史信息编码进隐藏状态；每个时刻的输出依赖于“当前输入+所有历史输入的累积”,相当于浓缩的上下文。

- [知识点] RNN缺点：
    - RNN计算成本高
    - 序列相关的关系只能通过参数来调整，远距离关系易被忽视。

- [QA] Q: **门机制可以做哪些优化？**
    > A: 
    1. **遗忘门（Forget Gate）**：
    - 功能：决定上一时刻隐藏状态 \( h_{t-1} \) 中哪些信息被保留（如文本中“小明”的指代信息）、哪些被遗忘（无关冗余词）。
    - 优化点：避免远距离信息被“梯度消失”冲刷，强化长距离依赖。
    2. **输入门（Input Gate）**：
    - 功能：决定当前时刻输入 \( x_t \) 中哪些信息被纳入隐藏状态（如关键实体、逻辑词）。
    - 优化点：过滤噪声，聚焦核心信息，减少无效参数调整。
    3. **输出门（Output Gate）**：
    - 功能：决定隐藏状态中哪些信息输出到下一时刻（如当前词的语义是否需要传递给下一个词）。
    - 优化点：动态控制信息传递，避免无关信息干扰后续计算。
    4. **GRU的简化优化**：将遗忘门和输入门合并为“更新门”，保留“重置门”，在减少参数的同时保持长依赖建模能力，降低计算成本。

- [QA] Q：**注意力机制最初在cv领域是怎么被提出来的？又是怎么被迁移到NLP领域的？**是否存在某种类比关系导致可以实现这个迁移？
    > A: **模拟人类视觉的“选择性关注”**——人类观察图像时会聚焦关键区域（如人脸的眼睛），而非平等处理所有像素。（2014年《Recurrent Models of Visual Attention》（Mnih et al.），提出“硬注意力”（Hard Attention，直接选择部分区域）和“软注意力”（Soft Attention，对所有区域加权），用于解决图像分类、目标检测中的“信息过载”问题（如高分辨率图像的像素冗余）。）
    迁移的转折点：2017年Transformer论文《Attention Is All You Need》，首次将“缩放点积注意力”引入NLP，彻底替代RNN作为核心架构。
    CV中是“图像区域的关联”，NLP中是“token的关联”，本质都是“对结构化数据的选择性信息聚合”。

- [QA] Q：**注意力机制在CV领域是不是可以抽象理解**为画面中一个框？如果是，这个框和注意力机制的三个核心变量（Query、Key、Value）之间的关系是？
    > A: 可以这么理解，但不是一个严格的框。更准确的表述是热点图，**对图像中每个位置的“关注权重分布”**（软注意力）——权重高的区域相当于“框选的核心区域”，权重低的区域相当于“框外的次要区域”。
    与Q/K/V的对应关系
        - **Query（查询）**：当前任务目标（如“检测图像中的猫”“提取图像的边缘特征”），对应“关注框的选择标准”（比如“寻找猫的轮廓特征”）。
        - **Key（键）**：图像中每个区域的特征表示（如像素的纹理、局部卷积特征），对应“关注框的候选区域属性”（比如“某个区域是否有猫的耳朵特征”）。
        - **Value（值）**：图像中每个区域的原始/加工后特征（如像素值、高维卷积特征），对应“关注框内的实际信息内容”（比如“猫耳朵区域的具体像素数据”）。

- [QA] Q：类比NLP中呢？
    > A: 从某个词（query）出发对文本（Key/Value）的每一个token的相对注意分布；Query和Key的相关性

- [QA] 什么叫：通过计算Query与Key的相关性“为真值加权求和”
    > A: “真值”指Value（需要被聚合的原始信息，如NLP中的token向量、CV中的区域特征）；“加权求和”是根据Query与Key的相关性，给每个Value分配不同权重，再累加得到最终的注意力输出。
    #### 示例（NLP场景）
    假设文本是“小明喜欢吃苹果，他每天都买”，当前Query是“他”（想知道“他”指代谁）：
    1. Key是所有token的特征（“小明”“喜欢”“吃”“苹果”“他”“每天”“买”）；
    2. 计算Query（“他”）与每个Key的相关性：“小明”的相关性最高（权重0.8），其他token权重极低（如“喜欢”0.05、“苹果”0.03）；
    3. **Value是所有token的原始词向量；**
    4. 加权求和：0.8×“小明”的向量 + 0.05×“喜欢”的向量 + ... + 0.03×“苹果”的向量 → 最终输出聚焦于“小明”的特征向量，即“他”的注意力结果指向“小明”。

- [QA] 如何针对query，赋予每一个key权重？（对于每个query，每个key的权重都不同吗？）
    > A: 都不同。

- [知识点] 词向量：词义相近的词在向量空间中距离更近；距离：欧氏距离or**向量点积**

- [QA] Q: 点积的几何意义？相似大于0，不相似小于0？）
    > A: 
    点积的公式为：
    $$a \cdot b = |a||b|\cos\theta$$
    其中 \( \theta \) 是两向量的夹角，其本质是：
    > “一个向量在另一个向量方向上的投影长度，乘以另一个向量的模长”
    ### 点积与向量方向的关系
    - 当两向量方向一致，点积达到最大值；
    - 当两向量垂直，点积为0；
    - 当两向量方向相反，点积达到最小值。
    ### 相似性判断
    点积的正负**不直接等同于“相似/不相似”**，而是反映“向量方向是否一致”：
    - 点积>0：两向量夹角<90°，方向大致相同（语义倾向一致，如“猫”和“狗”都是动物）；
    - 点积=0：两向量垂直，无直接关联（如“猫”和“桌子”）；
    - 点积<0：两向量夹角>90°，方向相反（语义倾向相反，如“喜欢”和“讨厌”）。
    ⚠️ 注意：
    相似性需结合向量模长判断——**将向量归一化后（\( |a|=|b|=1 \)）**，点积直接等于 \( \cos\theta \)（取值范围[-1,1]），此时“点积越大，向量的相似性越高”。

- [QA] Q：为什么最终的注意力计算要乘以V？
    > A: 
        1. Query和Key的作用：仅用于计算“哪些信息重要”（权重），但它们本身不包含“需要输出的具体内容”；
        2. Value的作用：存储每个位置的原始/加工后特征（如NLP中的词语义、CV中的图像区域细节），是“权重作用的对象”；
        3. 乘法的意义：将“重要性权重”与“实际信息”绑定——高权重的Value（重要信息）在输出中占比更高，低权重的Value（次要信息）占比更低，最终输出是“筛选后的有效信息聚合”。
        4. 反例（如果不乘V）
        若仅用Query与Key的权重输出，相当于“只知道哪些信息重要，但没提取这些信息的内容”，无法形成有意义的特征表示（比如只知道“小明”与“他”相关，但没得到“小明”的语义向量，就无法完成指代消解任务）。
- [QA] Q：怎么理解“如果Q和K对应的维度dk比较大，softmax放缩时非常容易受影响”
    > A: ![豆包的解释](./pics/cap01.png)






